{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2009 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdd_hdd = None\n",
    "for i in range(1, 13):\n",
    "    monthly_path = \"2009/2009%02dmonthly.txt\" % i\n",
    "    station_path = \"2009/2009%02dstation.txt\" % i\n",
    "    monthly = pd.read_csv(monthly_path, na_values='M')\n",
    "    cdd_hdd_month = monthly[['WBAN', 'YearMonth', 'HeatingDegreeDays', 'CoolingDegreeDays']]\n",
    "    if cdd_hdd is None:\n",
    "        cdd_hdd = cdd_hdd_month\n",
    "    else:\n",
    "        cdd_hdd = pd.concat([cdd_hdd, cdd_hdd_month])\n",
    "    stations = pd.read_csv(station_path, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def valid_length(column):\n",
    "    if len(column) == 12:\n",
    "        return [1 for elem in column]\n",
    "    else:\n",
    "        return [0 for elem in column]\n",
    "    \n",
    "cdd_hdd = cdd_hdd[cdd_hdd.groupby('WBAN')['YearMonth'].transform(valid_length) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def valid_column(column):\n",
    "    for elem in column:\n",
    "        if np.isnan(elem):\n",
    "            return [0 for e in column]\n",
    "    return [1 for e in column]\n",
    "    \n",
    "cdd_hdd = cdd_hdd[cdd_hdd.groupby('WBAN')['CoolingDegreeDays'].transform(valid_column) == 1]\n",
    "cdd_hdd = cdd_hdd[cdd_hdd.groupby('WBAN')['HeatingDegreeDays'].transform(valid_column) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station_cdd_hdd = cdd_hdd.groupby('WBAN')[['HeatingDegreeDays', 'CoolingDegreeDays']].aggregate(np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30 Year Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "separations = [0, 7, 27]\n",
    "separations += np.arange(30, 114, 6).tolist()\n",
    "separations += [114]\n",
    "\n",
    "rows = []\n",
    "with open('30yr.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        row = []\n",
    "        for i in range(len(separations) - 1):\n",
    "            row.append(line[separations[i]:separations[i+1]].strip())\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "climate_norm = pd.DataFrame(rows, columns=['COOP', 'Name', 'State',\n",
    "                            'HDD65', 'HDD60', 'HDD57',\n",
    "                            'HDD55', 'HDD50', 'HDD45', 'HDD40',\n",
    "                            'CDD70', 'CDD65', 'CDD60', 'CDD57',\n",
    "                            'CDD55', 'CDD50', 'CDD45'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "climate_norm.to_csv('30yr.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "separations\n",
    "rows = []\n",
    "with open('emshr_lite.txt', encoding='latin1') as f:\n",
    "    headers = f.readline().strip().split()\n",
    "    loc_str = f.readline().strip()\n",
    "    separations = np.where(np.array([0 if c == '-' else 1 for c in loc_str]))[0].tolist()\n",
    "    separations = [0] + separations + [len(loc_str)]\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        row = []\n",
    "        for i in range(len(separations) - 1):\n",
    "            row.append(line[separations[i]:separations[i+1]].strip())\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations = pd.DataFrame(rows, columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations.to_csv('station_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normals 1981-2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Name      | Position | Type\n",
    "   ----------|----------|-----------\n",
    "     STNID   |    1- 11 | Character \n",
    "     VALUE   |  19- 23  | Integer   \n",
    "     FLAG    |  24- 24  | Character "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "with open('ann-htdd-normal.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        station, value_flag = line.strip().split()\n",
    "        value = int(value_flag[:-1])\n",
    "        if value < 0:\n",
    "            value = np.nan\n",
    "        flag = value_flag[-1]\n",
    "        row = [station, value, flag]\n",
    "        rows.append(row)\n",
    "hdd = pd.DataFrame(rows, columns=['StationId', 'HDD30', 'HDD30Flag'])\n",
    "\n",
    "rows = []\n",
    "with open('ann-cldd-normal.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        station, value_flag = line.strip().split()\n",
    "        value = int(value_flag[:-1])\n",
    "        if value < 0:\n",
    "            value = np.nan\n",
    "        flag = value_flag[-1]\n",
    "        row = [station, value, flag]\n",
    "        rows.append(row)\n",
    "cdd = pd.DataFrame(rows, columns=['StationId', 'CDD30', 'CDD30Flag'])\n",
    "\n",
    "cdd_hdd = pd.merge(hdd, cdd, on='StationId')\n",
    "cdd_hdd.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       \n",
    "      Name       | Pos     | Type\n",
    "      -----------|---------|-------------\n",
    "       ID        |    1-11 |  Character\n",
    "       LATITUDE  |   13-20 |  Real\n",
    "       LONGITUDE |   22-30 |  Real\n",
    "       ELEVATION |   32-37 |  Real\n",
    "       STATE     |   39-40 |  Character\n",
    "       NAME      |   42-71 |  Character\n",
    "       GSNFLAG   |   73-75 |  Character\n",
    "       HCNFLAG   |   77-79 |  Character\n",
    "       WMOID     |   81-85 |  Character\n",
    "       METHOD \t |   87-99 |  Character\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "with open('temp-inventory.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        station = line[:11]\n",
    "        lat = float(line[12:20])\n",
    "        lng = float(line[21:30])\n",
    "        rows.append([station, lat, lng])\n",
    "stations = pd.DataFrame(rows, columns=['StationId', 'Lat', 'Lng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdd_hdd_loc = pd.merge(cdd_hdd, stations, on='StationId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdd_hdd_loc[['Lat', 'Lng', 'CDD30', 'HDD30']].to_csv('30yr_with_location_recent.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "climate_norm = pd.read_csv('30yr.csv')\n",
    "stations = pd.read_csv('station_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat_lng_cdd_hdd = pd.merge(stations, climate_norm, on=['COOP']).groupby('COOP').nth(0)[['LAT_DEC', 'LON_DEC', 'HDD65', 'CDD65']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat_lng_cdd_hdd.rename(columns={'LAT_DEC': 'Lat', 'LON_DEC': 'Lng', 'HDD65': 'HDD30', 'CDD65': 'CDD30'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat_lng_cdd_hdd.to_csv('30yr_with_location.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
