{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "Here we normalize the census variables to a format that is easy to interpret.\n",
    "\n",
    "Census variables come in the format:\n",
    "\n",
    "`TENURE BY AGE OF HOUSEHOLDER BY OCCUPANTS PER ROOM% Owner occupied:% Householder 15 to 34 years:% 1.01 to 1.50 occupants per room`\n",
    "\n",
    "Each field is separated by a `%`. There are typically summary variables for all subfields of a particular field. For example, the following variables also exist:\n",
    "\n",
    "`TENURE BY AGE OF HOUSEHOLDER BY OCCUPANTS PER ROOM% Owner occupied:% Householder 15 to 34 years:`\n",
    "\n",
    "`TENURE BY AGE OF HOUSEHOLDER BY OCCUPANTS PER ROOM% Owner occupied:`\n",
    "\n",
    "`TENURE BY AGE OF HOUSEHOLDER BY OCCUPANTS PER ROOM for Occupied housing units`\n",
    "\n",
    "The last variable is the root variable, which names the total population described by the table (all of its subfields).\n",
    "\n",
    "The number of fields is the depth of that particular variable. Within any census table, there are variables of many different depths. Sometimes the data is tabular and the maximum depth is the same for all parts of the table. Other times, the data is not tabular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Selection\n",
    "We load variables.json as our schema. We use model-variables.csv to select only the variables we want to normalize. To initially populate model-variables.csv, use the code below to get all variables from a subset of tables deemed to be relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# desiredTables = [\"B08006\",\n",
    "# \"B19001\",\n",
    "# \"B19051\",\n",
    "# \"B19054\",\n",
    "# \"B19056\",\n",
    "# \"B19057\",\n",
    "# \"B19059\",\n",
    "# \"B19060\",\n",
    "# \"B22010\",\n",
    "# \"B25003\",\n",
    "# \"B25006\",\n",
    "# \"B25007\",\n",
    "# \"B25009\",\n",
    "# \"B25013\",\n",
    "# \"B25020\",\n",
    "# \"B25024\",\n",
    "# \"B25032\",\n",
    "# \"B25036\",\n",
    "# \"B25038\",\n",
    "# \"B25040\",\n",
    "# \"B25042\",\n",
    "# \"B25069\",\n",
    "# \"C17002\"]\n",
    "\n",
    "# for tableId in desiredTables:\n",
    "#     for varId in data['tables'][tableId]['variables']:\n",
    "#         print(varId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refine these selections in select.html so that the data is tabular. Once the right variables have been selected, load the selections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "with open(\"variables.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "with open(\"model-variables.csv\") as f:\n",
    "    selected_variables = set(line.strip() for line in f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the tables whose variables are relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tables = []\n",
    "\n",
    "for tableId in data['tableIds']:\n",
    "    table = data['tables'][tableId]\n",
    "    \n",
    "    # Get all variables for this table that have been selected\n",
    "    varlist = [\n",
    "        data['variables'][variableId] for variableId in table['variables']\n",
    "        if (variableId in selected_variables)]\n",
    "    if len(varlist) == 0:\n",
    "        continue\n",
    "    tables.append((table, varlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this section is to turn flat lists of census variables into n-d tables of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the variable names given in the census data to eliminate extraneous characters\n",
    "\n",
    "def normalize_desc(d):\n",
    "    return d.strip(\" :%\")\n",
    "\n",
    "def normalize_field(f):\n",
    "    f = f.strip(\" :-\").lower()\n",
    "    return re.sub(\"\\s+\", \" \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if a list of variables can be interpreted as an n-d array\n",
    "\n",
    "def tabular(varlist):\n",
    "    cross_product = set(var.fields for var in varlist)\n",
    "    labels = [set(s) for s in zip(*cross_product)]\n",
    "    full_cross_product = set(itertools.product(*labels))\n",
    "    cross_product = set(var.fields for var in varlist)\n",
    "    return full_cross_product == cross_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class Variable:\n",
    "    \"\"\"The variable class is structured like a tree. Each element has some number of children.\n",
    "    The goal of this class is to take this tree structure and convert it into a tabular form.\n",
    "    \"\"\"\n",
    "    def __init__(self, fields, id):\n",
    "        self.fields = tuple(fields)\n",
    "        self.id = id\n",
    "        self.key = fields[-1]\n",
    "        self.depth = len(fields) - 1\n",
    "        self.parent = None\n",
    "        self.children = []\n",
    "        self.child_keys = []\n",
    "        \n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "        self.child_keys.append(child.key)\n",
    "        child.parent = self\n",
    "        \n",
    "    def get_max_depth(self):\n",
    "        if len(self.children) > 0:\n",
    "            self.max_depth = max(child.get_max_depth() for child in self.children)\n",
    "        else:\n",
    "            self.max_depth = self.depth\n",
    "        return self.max_depth\n",
    "    \n",
    "    def get_min_depth(self):\n",
    "        if len(self.children) > 0:\n",
    "            self.min_depth = min(child.get_min_depth() for child in self.children)\n",
    "        else:\n",
    "            self.min_depth = self.depth\n",
    "        return self.min_depth\n",
    "    \n",
    "    def deepest(self, clip_depth = None):\n",
    "        \"\"\"Returns a list of the deepest elements in this table, skipping summary counts\"\"\"\n",
    "        self.get_max_depth()\n",
    "        if clip_depth is None:\n",
    "            clip_depth = self.get_min_depth()\n",
    "        for child in self.walk():\n",
    "            if child.depth == child.max_depth:\n",
    "                yield child.clip_id_to_depth(clip_depth)\n",
    "                \n",
    "    def table(self, clip_depth = None):\n",
    "        \"\"\"Returns a list of the deepest elements in this table in tabular form as a numpy array\"\"\"\n",
    "        if clip_depth is None:\n",
    "            clip_depth = self.get_min_depth()\n",
    "        t = self._table(clip_depth)\n",
    "        if not isinstance(t, np.ndarray):\n",
    "            t = np.array(t)\n",
    "        return t\n",
    "        \n",
    "    def _table(self, clip_depth):\n",
    "        \"\"\"Recursive function call for table\"\"\"\n",
    "        if self.depth == self.max_depth:\n",
    "            return self.clip_id_to_depth(clip_depth)\n",
    "        else:\n",
    "            return np.array([child._table(clip_depth) for child in self.children])\n",
    "    \n",
    "    def walk(self):\n",
    "        \"\"\"Generator for all elements in this tree\"\"\"\n",
    "        yield self\n",
    "        for child in self.children:\n",
    "            for var in child.walk():\n",
    "                yield var\n",
    "    \n",
    "    def clip_id_to_depth(self, depth):\n",
    "        \"\"\"Combine any fields past a certain depth into one combination field.\n",
    "        \n",
    "        For example ('male', 20 to 25 years', 'income > 5000') would be clipped to\n",
    "        ('male', '20 to 25 years - income > 5000')\n",
    "        \n",
    "        This is a way of making a tree tabular if it is partially tabular (a field always\n",
    "        has subfields, but other fields at the same depth never have subfields).\n",
    "        \"\"\"\n",
    "        new_fields = self.fields[:depth] + (\"-\".join(self.fields[depth:]),)\n",
    "        return Variable(new_fields, self.id)\n",
    "    \n",
    "    def filter_to_depth(self, depth):\n",
    "        \"\"\"Eliminate any fields beyond a certain depth.\"\"\"\n",
    "        new = Variable(self.fields, self.id)\n",
    "        if self.depth < depth:\n",
    "            for child in self.children:\n",
    "                new.add_child(child.filter_to_depth(depth))\n",
    "        return new\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<Variable \" + \"%\".join(self.fields) + \">\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def parse_table(table, varlist):\n",
    "    \"\"\"Return a numpy array of Variable objects.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table: dict from `variables.json`\n",
    "    \n",
    "    varlist: list of Variable objects\n",
    "    \"\"\"\n",
    "    \n",
    "    # Map from fields to variable\n",
    "    all_variables = {}\n",
    "    \n",
    "    for var in varlist:\n",
    "        # Parse the variable names from the census schema\n",
    "        desc = normalize_desc(var['description'])\n",
    "        fields = [normalize_field(f) for f in desc.split('%')]\n",
    "        \n",
    "        # Avoid issues with root variable\n",
    "        fields[0] = table['description']\n",
    "        if fields[-1] == 'total':\n",
    "            fields = fields[:-1]\n",
    "            \n",
    "        v = Variable(fields, var['id'])\n",
    "        all_variables[v.fields] = v\n",
    "        \n",
    "        # Link tree structure together\n",
    "        parent_fields = tuple(fields[:-1])\n",
    "        if parent_fields in all_variables:\n",
    "            all_variables[parent_fields].add_child(v)\n",
    "        \n",
    "    # Find root\n",
    "    root_key = (table['description'],)\n",
    "    if not root_key in all_variables:\n",
    "        print(all_variables)\n",
    "        print(table['id'])\n",
    "    root = all_variables[root_key]\n",
    "    \n",
    "    # Find best depth\n",
    "    max_depth = root.get_max_depth()\n",
    "    min_depth = root.get_min_depth()\n",
    "    \n",
    "    # Try combinations of flattening and filtering to make the data tabular\n",
    "    valid_depths = np.zeros((max_depth + 1, max_depth + 1))\n",
    "    for filter_depth in range(max_depth, -1, -1):\n",
    "        for clip_depth in range(min(min_depth, filter_depth), -1, -1):\n",
    "            tablevars = list(root.filter_to_depth(filter_depth).deepest(clip_depth))\n",
    "            if tabular(tablevars):\n",
    "                valid_depths[filter_depth, clip_depth] = 1\n",
    "    \n",
    "    # Get best combination\n",
    "    max_tabular_depth = np.argmax(np.max(valid_depths, 0) * np.arange(max_depth + 1))\n",
    "    if max_depth != max_tabular_depth:\n",
    "        print(\"Warning: Clipping table %s from %d to %d\" % (table['description'], max_depth, max_tabular_depth))\n",
    "    \n",
    "    full_table = list(root.deepest())\n",
    "    \n",
    "    if not tabular(full_table):\n",
    "        print(\"Not tabular\")\n",
    "        print(table['id'])\n",
    "        print(table['description'])\n",
    "        print('')\n",
    "        return None\n",
    "    \n",
    "    return root.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate variables, a list of numpy arrays of variables. We have converted the data into a tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variables = []\n",
    "for i, t in enumerate(tables):\n",
    "    table, varlist = t\n",
    "    tablevars = parse_table(table, varlist)\n",
    "    if tablevars is None:\n",
    "        raise Exception('Could not parse table %s' % table['description'])\n",
    "    else:\n",
    "        variables.append(tablevars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " def make_labels(group):\n",
    "    \"\"\" Get a set of labels for each dimension\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    group: list of Variable\n",
    "    \"\"\"\n",
    "    flat = group.flatten()\n",
    "    return [frozenset(s) for s in zip(*[var.fields[1:] for var in flat])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate labels, which is an set of sets of fields that occur together. For example, the labels object for heating fuel will contain the strings:\n",
    "\n",
    "`'bottled, tank, or lp gas',\n",
    "'coal or coke',\n",
    "'electricity',\n",
    "'fuel oil, kerosene, etc.',\n",
    "'no fuel used',\n",
    "'other fuel',\n",
    "'solar energy',\n",
    "'utility gas',\n",
    "'wood'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = set()\n",
    "\n",
    "for group in variables:\n",
    "    labels = labels.union(set(make_labels(group)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Name Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this section is to interpret the names of variables, i.e. `built from 1950 to 1959` into useful forms like `('built', 'range', 1950, 1959)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_pattern = \"(?:(?:[0-9]+(?:\\.[0-9]*)?)|(?:\\.[0-9]+))\"\n",
    "dollar_pattern = \"\\$[0-9]+(?:,[0-9][0-9][0-9])*(?:\\.[0-9]*)?\"\n",
    "\n",
    "# Generate a dict\n",
    "patterns = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct rules for each group of fields. This is not scalable, but it is not that slow either.\n",
    "\n",
    "* `patterns` is a dictionary from \n",
    "    * kev: a group of field labels (`frozenset(str)`) to\n",
    "    * value: `list` of tuples\n",
    "        * `str` regex pattern\n",
    "        * parser function from\n",
    "            * input: `m`, a regex match object to\n",
    "            * output: `tuple('field name', 'type', ...)` or list of tuples where `type` is 'category', 'range',\n",
    "            or 'exact'. 'field name' should be the category that all of the field labels fall into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorical_as_is(name):\n",
    "    return [\n",
    "        (\n",
    "            '.*',\n",
    "            lambda m: (name, 'category', m.group(0))\n",
    "        )\n",
    "    ]\n",
    "\n",
    "def categorical_replacement(name, replacements):\n",
    "    def parse(m):\n",
    "        match = m.group(0)\n",
    "        for from_patt, to_patt in replacements:\n",
    "            match = re.sub(from_patt, to_patt, match)\n",
    "        return (name, 'category', match)\n",
    "    return [('.*', parse)]\n",
    "    \n",
    "def categorical_pairs(name, replacements):\n",
    "    return [(\n",
    "           from_patt,\n",
    "            lambda m: (name, 'category', to_patt)\n",
    "    ) for from_patt, to_patt in replacements]\n",
    "\n",
    "def numerical_match(name, range_pattern=None,\n",
    "                    bottom_pattern=None, exact_pattern=None,\n",
    "                    top_pattern=None, dtype=int):\n",
    "    p = []\n",
    "    if range_pattern:\n",
    "        p.append((\n",
    "                range_pattern,\n",
    "                lambda m: (name, 'range', dtype(m.group(1)), dtype(m.group(2)))\n",
    "            ))\n",
    "    if exact_pattern:\n",
    "        p.append((\n",
    "                exact_pattern,\n",
    "                lambda m: (name, 'exact', dtype(m.group(1)))\n",
    "            ))\n",
    "    if bottom_pattern:\n",
    "        p.append((\n",
    "                bottom_pattern,\n",
    "                lambda m: (name, 'range', -np.inf, dtype(m.group(1)))\n",
    "            ))\n",
    "    if top_pattern:\n",
    "        p.append((\n",
    "                top_pattern,\n",
    "                lambda m: (name, 'range', dtype(m.group(1)), np.inf)\n",
    "            ))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns[frozenset({\n",
    "            'high school graduate (including equivalency)', \"some college or associate's degree\",\n",
    "            'less than high school graduate', \"bachelor's degree or higher\"})] = categorical_as_is('education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patterns[frozenset([\n",
    "            'under .50', '1.25 to 1.49', '1.50 to 1.84', '.50 to .99',\n",
    "            '1.85 to 1.99', '2.00 and over', '1.00 to 1.24'])] = \\\n",
    "    numerical_match('poverty to income',\n",
    "                    range_pattern=\"(%s) to (%s)\" % (num_pattern, num_pattern),\n",
    "                    bottom_pattern=\"under (%s)\" % (num_pattern,),\n",
    "                    top_pattern=\"(%s) and over\" % (num_pattern,),\n",
    "                    dtype=float\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns[frozenset(['renter occupied',\n",
    "                    'owner occupied'])] = \\\n",
    "    categorical_replacement('own_rent', [\n",
    "        ('er .*', ''),\n",
    "    ])\n",
    "\n",
    "patterns[frozenset({\n",
    "            'owner-occupied housing units', 'renter-occupied housing units'\n",
    "        })] = \\\n",
    "    categorical_replacement('own_rent', [\n",
    "        ('er-.*', ''),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns[frozenset({'households with no persons with a disability',\n",
    "                    'households with 1 or more persons with a disability'\n",
    "                   })] = \\\n",
    "    categorical_pairs('disability', [\n",
    "        ('with no', 'no'),\n",
    "        ('with 1 or more', 'yes'),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def with_without(name):\n",
    "    return categorical_pairs(name, [('with', 'yes'), ('no', 'no')])\n",
    "\n",
    "patterns[frozenset(['with earnings', 'no earnings'])] = with_without('earnings')\n",
    "\n",
    "patterns[frozenset({'no other types of income',\n",
    "                    'with other types of income'})] = with_without('other income')\n",
    "\n",
    "patterns[frozenset({'no retirement income',\n",
    "                    'with retirement income'})] = with_without('retirement income')\n",
    "\n",
    "patterns[frozenset({'with public assistance income',\n",
    "                    'no public assistance income'})] = with_without('assistance income')\n",
    "\n",
    "patterns[frozenset({'no supplemental security income (ssi)',\n",
    "                    'with supplemental security income (ssi)'})] = with_without('supplemental security income')\n",
    "\n",
    "patterns[frozenset([\n",
    "            'with interest, dividends, or net rental income',\n",
    "            'no interest, dividends, or net rental income'])] = with_without('investment income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patterns[frozenset(['wood', 'solar energy', 'other fuel', 'electricity',\n",
    "                    'utility gas', 'bottled, tank, or lp gas', 'coal or coke',\n",
    "                    'fuel oil, kerosene, etc.', 'no fuel used'])] = \\\n",
    "    categorical_pairs('fuel source', [\n",
    "            ('solar', 'solar'),\n",
    "            ('other', 'other'),\n",
    "            ('utility gas', 'natural gas'),\n",
    "            ('lp', 'propane'),\n",
    "            ('coal', 'coal'),\n",
    "            ('fuel oil', 'fuel oil or kerosene'),\n",
    "            ('no fuel', 'none')\n",
    "        ]) + categorical_as_is('fuel source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns[frozenset([\n",
    "            '5-person household', '2-person household', '4-person household',\n",
    "            '7-or-more person household', '1-person household',\n",
    "            '3-person household', '6-person household'])] = \\\n",
    "    numerical_match('household size',\n",
    "                    exact_pattern=\"(%s)-person\" % (num_pattern,),\n",
    "                    top_pattern=\"(%s)-or-more\" % (num_pattern,)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patterns[frozenset(['no extra payment for any utilities', 'pay extra for one or more utilities'])] = \\\n",
    "    categorical_pairs('pay for utility', [\n",
    "        ('^no', 'none'),\n",
    "        ('^pay', 'some or all')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns[frozenset({'household did not receive food stamps/snap in the past 12 months',\n",
    "                    'household received food stamps/snap in the past 12 months'})] = \\\n",
    "    categorical_pairs('food stamps', [\n",
    "            ('did not', 'no'),\n",
    "            ('received', 'yes')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dollar_to_num(s):\n",
    "    return int(s.replace('$', '').replace(',', ''))\n",
    "\n",
    "patterns[frozenset(['$100,000 to $124,999', '$40,000 to $44,999', '$75,000 to $99,999', '$35,000 to $39,999',\n",
    "                    '$60,000 to $74,999', '$125,000 to $149,999', '$30,000 to $34,999', '$25,000 to $29,999',\n",
    "                    '$50,000 to $59,999', '$200,000 or more', '$45,000 to $49,999', '$150,000 to $199,999',\n",
    "                    '$10,000 to $14,999', '$20,000 to $24,999', 'less than $10,000', '$15,000 to $19,999'])] = \\\n",
    "    numerical_match('household income',\n",
    "                   range_pattern='(%s) to (%s)' % (dollar_pattern, dollar_pattern),\n",
    "                   top_pattern='(%s) or more' % (dollar_pattern,),\n",
    "                   bottom_pattern='less than (%s)' % (dollar_pattern,),\n",
    "                   dtype=dollar_to_num\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns[frozenset({'taxicab, motorcycle, or other means', 'bus or trolley bus', 'carpooled', 'subway or elevated',\n",
    "                    'worked at home', 'bicycle', 'walked', 'in 4-or-more-person carpool',\n",
    "                    'streetcar or trolley car (carro publico in puerto rico)', 'public transportation (excluding taxicab)',\n",
    "                    'railroad', 'in 2-person carpool', 'car, truck, or van', 'drove alone', 'in 3-person carpool', 'ferryboat'})] = [\n",
    "    (\n",
    "        'worked at home',\n",
    "        lambda m: [\n",
    "            ('transportation', 'category', m.group(0)),\n",
    "            ('work from home', 'category', 'yes'),\n",
    "        ]\n",
    "    ),(\n",
    "        '.*',\n",
    "        lambda m: [\n",
    "            ('transportation', 'category', m.group(0)),\n",
    "            ('work from home', 'category', 'no'),\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patterns[frozenset({'50 or more', 'boat, rv, van, etc.',\n",
    "                    '5 to 9', '20 to 49',\n",
    "                    'mobile home', '1, attached',\n",
    "                    '2', '10 to 19', '3 or 4',\n",
    "                    '1, detached'})] = [\n",
    "    (\n",
    "        '(%s) to (%s)' % (num_pattern, num_pattern),\n",
    "        lambda m: [\n",
    "            ('num units', 'range', int(m.group(1)), int(m.group(2))),\n",
    "            ('building type', 'category', 'apartment')\n",
    "        ]\n",
    "    ),(\n",
    "        '(%s) or more' % (num_pattern,),\n",
    "        lambda m: [\n",
    "            ('num units', 'range', int(m.group(1)), np.inf),\n",
    "            ('building type', 'category', 'apartment')\n",
    "        ]\n",
    "    ),(\n",
    "        'mobile',\n",
    "        lambda m: [\n",
    "            ('num units', 'exact', 1),\n",
    "            ('building type', 'category', 'mobile home')\n",
    "        ]\n",
    "    ),(\n",
    "        '1, attached',\n",
    "        lambda m: [\n",
    "            ('num units', 'exact', 1),\n",
    "            ('building type', 'category', 'single family attached')\n",
    "        ]\n",
    "    ),(\n",
    "        '1, detached',\n",
    "        lambda m: [\n",
    "            ('num units', 'exact', 1),\n",
    "            ('building type', 'category', 'single family detached')\n",
    "        ]\n",
    "    ),(\n",
    "        '2',\n",
    "        lambda m: [\n",
    "            ('num units', 'exact', 2),\n",
    "            ('building type', 'category', 'apartment')\n",
    "        ]\n",
    "    ),(\n",
    "        '3 or 4',\n",
    "        lambda m: [\n",
    "            ('num units', 'range', 3, 4),\n",
    "            ('building type', 'category', 'apartment')\n",
    "        ]\n",
    "    ),(\n",
    "        'boat',\n",
    "        lambda m: [\n",
    "            ('num units', 'exact', 1),\n",
    "            ('building type', 'category', 'other')\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def small_count(name, suffix):\n",
    "    return [(\n",
    "        '^no %s' % (suffix,),\n",
    "        lambda m: (name, 'exact', 0)\n",
    "    ),(\n",
    "        '(%s) %s' % (num_pattern, suffix),\n",
    "        lambda m: (name, 'exact', int(m.group(1)))\n",
    "    ),(\n",
    "        '(%s) or more' % (num_pattern,),\n",
    "        lambda m: (name, 'range', int(m.group(1)), np.inf)\n",
    "    )]\n",
    "    \n",
    "    \n",
    "patterns[frozenset({'no bedroom', '2 bedrooms', '3 bedrooms',\n",
    "                    '1 bedroom', '5 or more bedrooms', '4 bedrooms'})] = small_count('bedrooms', 'bedroom')\n",
    "\n",
    "patterns[frozenset({\n",
    "            '5 rooms', '6 rooms', '3 rooms', '4 rooms', '2 rooms',\n",
    "            '1 room', '7 rooms', '9 or more rooms', '8 rooms'})] = small_count('rooms', 'room')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns[frozenset({\n",
    "            'householder who is black or african american alone', 'householder who is white alone',\n",
    "            'householder who is asian alone', 'householder who is two or more races',\n",
    "            'householder who is native hawaiian and other pacific islander alone',\n",
    "            'householder who is american indian and alaska native alone',\n",
    "            'householder who is some other race alone'})] = [\n",
    "    (\n",
    "        '.* alone',\n",
    "        lambda m: ('householder race', 'category', m.group(0).replace('householder who is ','').replace(' alone',''))\n",
    "    ),(\n",
    "        'two or more',\n",
    "        lambda m: ('householder race', 'category', 'two or more')\n",
    "    ),(\n",
    "        'some other',\n",
    "        lambda m: ('householder race', 'category', 'other')\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def year_range(name):\n",
    "    return numerical_match(\n",
    "        name,\n",
    "        range_pattern=\"(%s) to (%s)\" % (num_pattern, num_pattern),\n",
    "        top_pattern=\"(%s) or later\" % (num_pattern,),\n",
    "        bottom_pattern=\"(%s) or earlier\" % (num_pattern,),\n",
    "    )\n",
    "\n",
    "patterns[frozenset([\n",
    "            'built 1970 to 1979', 'built 2010 or later', 'built 1980 to 1989',\n",
    "            'built 1950 to 1959', 'built 1940 to 1949', 'built 1960 to 1969',\n",
    "            'built 2000 to 2009', 'built 1939 or earlier',\n",
    "            'built 1990 to 1999'])] = year_range('built')\n",
    "\n",
    "patterns[frozenset({'moved in 2010 or later', 'moved in 1970 to 1979', 'moved in 1990 to 1999',\n",
    "                    'moved in 2000 to 2009', 'moved in 1980 to 1989',\n",
    "                    'moved in 1969 or earlier'})] = year_range('moved in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns[frozenset({'householder 15 to 24 years', 'householder 85 years and over', 'householder 55 to 59 years',\n",
    "                    'householder 45 to 54 years', 'householder 60 to 64 years', 'householder 75 to 84 years',\n",
    "                    'householder 25 to 34 years', 'householder 35 to 44 years', 'householder 65 to 74 years'})] = \\\n",
    "    numerical_match(\n",
    "        'householder age',\n",
    "        range_pattern=\"(%s) to (%s)\" % (num_pattern, num_pattern),\n",
    "        top_pattern=\"(%s) years and over\" % (num_pattern,)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, use the code below to validate the patterns above. It will print any fields or field groups that are not matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bedrooms', 'exact', 3)\n",
      "('bedrooms', 'exact', 2)\n",
      "('bedrooms', 'exact', 4)\n",
      "('bedrooms', 'range', 5, inf)\n",
      "('bedrooms', 'exact', 0)\n",
      "('bedrooms', 'exact', 1)\n",
      "('supplemental security income', 'category', 'no')\n",
      "('supplemental security income', 'category', 'no')\n",
      "('built', 'range', -inf, 1939)\n",
      "('built', 'range', 2000, 2009)\n",
      "('built', 'range', 1980, 1989)\n",
      "('built', 'range', 1960, 1969)\n",
      "('built', 'range', 1990, 1999)\n",
      "('built', 'range', 2010, inf)\n",
      "('built', 'range', 1950, 1959)\n",
      "('built', 'range', 1940, 1949)\n",
      "('built', 'range', 1970, 1979)\n",
      "('food stamps', 'category', 'yes')\n",
      "('food stamps', 'category', 'yes')\n",
      "('household income', 'range', -inf, 10000)\n",
      "('household income', 'range', 100000, 124999)\n",
      "('household income', 'range', 150000, 199999)\n",
      "('household income', 'range', 200000, inf)\n",
      "('household income', 'range', 50000, 59999)\n",
      "('household income', 'range', 60000, 74999)\n",
      "('household income', 'range', 45000, 49999)\n",
      "('household income', 'range', 20000, 24999)\n",
      "('household income', 'range', 40000, 44999)\n",
      "('household income', 'range', 30000, 34999)\n",
      "('household income', 'range', 10000, 14999)\n",
      "('household income', 'range', 75000, 99999)\n",
      "('household income', 'range', 35000, 39999)\n",
      "('household income', 'range', 15000, 19999)\n",
      "('household income', 'range', 25000, 29999)\n",
      "('household income', 'range', 125000, 149999)\n",
      "[('num units', 'exact', 1), ('building type', 'category', 'single family attached')]\n",
      "[('num units', 'range', 5, 9), ('building type', 'category', 'apartment')]\n",
      "[('num units', 'range', 10, 19), ('building type', 'category', 'apartment')]\n",
      "[('num units', 'exact', 1), ('building type', 'category', 'single family detached')]\n",
      "[('num units', 'range', 20, 49), ('building type', 'category', 'apartment')]\n",
      "[('num units', 'range', 50, inf), ('building type', 'category', 'apartment')]\n",
      "[('num units', 'exact', 1), ('building type', 'category', 'mobile home')]\n",
      "[('num units', 'exact', 2), ('building type', 'category', 'apartment')]\n",
      "[('num units', 'exact', 1), ('building type', 'category', 'other')]\n",
      "[('num units', 'range', 3, 4), ('building type', 'category', 'apartment')]\n",
      "('earnings', 'category', 'no')\n",
      "('earnings', 'category', 'no')\n",
      "('householder race', 'category', 'black or african american')\n",
      "('householder race', 'category', 'some other race')\n",
      "('householder race', 'category', 'white')\n",
      "('householder race', 'category', 'native hawaiian and other pacific islander')\n",
      "('householder race', 'category', 'american indian and alaska native')\n",
      "('householder race', 'category', 'two or more')\n",
      "('householder race', 'category', 'asian')\n",
      "('education', 'category', 'less than high school graduate')\n",
      "('education', 'category', \"some college or associate's degree\")\n",
      "('education', 'category', \"bachelor's degree or higher\")\n",
      "('education', 'category', 'high school graduate (including equivalency)')\n",
      "('householder age', 'range', 45, 54)\n",
      "('householder age', 'range', 15, 24)\n",
      "('householder age', 'range', 35, 44)\n",
      "('householder age', 'range', 75, 84)\n",
      "('householder age', 'range', 65, 74)\n",
      "('householder age', 'range', 85, inf)\n",
      "('householder age', 'range', 60, 64)\n",
      "('householder age', 'range', 55, 59)\n",
      "('householder age', 'range', 25, 34)\n",
      "('assistance income', 'category', 'no')\n",
      "('assistance income', 'category', 'no')\n",
      "('household size', 'exact', 2)\n",
      "('household size', 'exact', 5)\n",
      "('household size', 'range', 7, inf)\n",
      "('household size', 'exact', 1)\n",
      "('household size', 'exact', 6)\n",
      "('household size', 'exact', 3)\n",
      "('household size', 'exact', 4)\n",
      "('rooms', 'exact', 6)\n",
      "('rooms', 'exact', 2)\n",
      "('rooms', 'exact', 7)\n",
      "('rooms', 'exact', 5)\n",
      "('rooms', 'exact', 4)\n",
      "('rooms', 'exact', 1)\n",
      "('rooms', 'exact', 3)\n",
      "('rooms', 'exact', 8)\n",
      "('rooms', 'range', 9, inf)\n",
      "('investment income', 'category', 'no')\n",
      "('investment income', 'category', 'no')\n",
      "[('transportation', 'category', 'in 2-person carpool'), ('work from home', 'category', 'no')]\n",
      "[('transportation', 'category', 'public transportation (excluding taxicab)'), ('work from home', 'category', 'no')]\n",
      "[('transportation', 'category', 'bus or trolley bus'), ('work from home', 'category', 'no')]\n",
      "[('transportation', 'category', 'taxicab, motorcycle, or other means'), ('work from home', 'category', 'no')]\n",
      "[('transportation', 'category', 'subway or elevated'), ('work from home', 'category', 'no')]\n",
      "[('transportation', 'category', 'bicycle'), ('work from home', 'category', 'no')]\n",
      "[('transportation', 'category', 'ferryboat'), ('work from home', 'category', 'no')]\n",
      "[('transportation', 'category', 'in 3-person carpool'), ('work from home', 'category', 'no')]\n",
      "[('transportation', 'category', 'carpooled'), ('work from home', 'category', 'no')]\n",
      "[('transportation', 'category', 'worked at home'), ('work from home', 'category', 'yes')]\n",
      "[('transportation', 'category', 'in 4-or-more-person carpool'), ('work from home', 'category', 'no')]\n",
      "[('transportation', 'category', 'streetcar or trolley car (carro publico in puerto rico)'), ('work from home', 'category', 'no')]\n",
      "[('transportation', 'category', 'drove alone'), ('work from home', 'category', 'no')]\n",
      "[('transportation', 'category', 'walked'), ('work from home', 'category', 'no')]\n",
      "[('transportation', 'category', 'car, truck, or van'), ('work from home', 'category', 'no')]\n",
      "[('transportation', 'category', 'railroad'), ('work from home', 'category', 'no')]\n",
      "('moved in', 'range', 1980, 1989)\n",
      "('moved in', 'range', 2000, 2009)\n",
      "('moved in', 'range', -inf, 1969)\n",
      "('moved in', 'range', 1990, 1999)\n",
      "('moved in', 'range', 1970, 1979)\n",
      "('moved in', 'range', 2010, inf)\n",
      "('pay for utility', 'category', 'some or all')\n",
      "('pay for utility', 'category', 'some or all')\n",
      "('own_rent', 'category', 'own')\n",
      "('own_rent', 'category', 'rent')\n",
      "('retirement income', 'category', 'no')\n",
      "('retirement income', 'category', 'no')\n",
      "('poverty to income', 'range', 1.25, 1.49)\n",
      "('poverty to income', 'range', 1.5, 1.84)\n",
      "('poverty to income', 'range', 1.85, 1.99)\n",
      "('poverty to income', 'range', 1.0, 1.24)\n",
      "('poverty to income', 'range', 2.0, inf)\n",
      "('poverty to income', 'range', 0.5, 0.99)\n",
      "('poverty to income', 'range', -inf, 0.5)\n",
      "('fuel source', 'category', 'electricity')\n",
      "('fuel source', 'category', 'none')\n",
      "('fuel source', 'category', 'none')\n",
      "('fuel source', 'category', 'none')\n",
      "('fuel source', 'category', 'wood')\n",
      "('fuel source', 'category', 'none')\n",
      "('fuel source', 'category', 'none')\n",
      "('fuel source', 'category', 'none')\n",
      "('fuel source', 'category', 'none')\n",
      "('disability', 'category', 'yes')\n",
      "('disability', 'category', 'yes')\n",
      "('own_rent', 'category', 'rent')\n",
      "('own_rent', 'category', 'own')\n",
      "('other income', 'category', 'no')\n",
      "('other income', 'category', 'no')\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for group in labels:\n",
    "    if group in patterns:\n",
    "        for label in group:\n",
    "            found = False\n",
    "            try: \n",
    "                for pattern, parser in patterns[group]:\n",
    "                    m = re.search(pattern, label)\n",
    "                    if m:\n",
    "                        print(parser(m))\n",
    "                        found = True\n",
    "                        break\n",
    "            except Exception:\n",
    "                pass\n",
    "            if not found:\n",
    "                print(label)\n",
    "    else:\n",
    "        print(group)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use these patterns to normalize the variable tables and generate metadata for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize_numerical(descriptors):\n",
    "    \"\"\"Take in a list of descriptor tuples and output metadata for a single field group.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    descriptors: list of tuple descriptors describing a single field group.\n",
    "    \"\"\"\n",
    "    # Get all the edges\n",
    "    edge_tuples = []\n",
    "    for d in descriptors:\n",
    "        if d[1] == 'exact':\n",
    "            edge_tuples.append((d[2], d[2]))\n",
    "        else:\n",
    "            edge_tuples.append((d[2], d[3]))\n",
    "            \n",
    "    # Sort the edges and return the order used for sorting\n",
    "    order = [t[1] for t in sorted(zip(edge_tuples, range(len(edge_tuples))))]\n",
    "    edge_tuples = list(sorted(edge_tuples))\n",
    "    \n",
    "    # Generate edges\n",
    "    edges = [edge_tuples[0][0]]\n",
    "    for i in range(len(descriptors) - 1):\n",
    "        # Take maximum on right side of bin, so that bins are left-inclusive right-exclusive\n",
    "        edges.append(max(edge_tuples[i][1],edge_tuples[i+1][0]))\n",
    "    edges.append(edge_tuples[i+1][1])\n",
    "    return {\n",
    "        'name': descriptors[0][0],\n",
    "        'edges': edges,\n",
    "        'labels': None,\n",
    "        'order': order,\n",
    "        'type': 'Continuous'\n",
    "    }\n",
    "\n",
    "def normalize_categorical(descriptors):\n",
    "    \"\"\"Take in a list of descriptor tuples and output metadata for a single field group.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    descriptors: list of tuple descriptors describing a single field group.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'name': descriptors[0][0],\n",
    "        'edges': None,\n",
    "        # Extract label from descriptors\n",
    "        'labels': [d[2] for d in descriptors],\n",
    "        'order': None,\n",
    "        'type': 'Categorical'\n",
    "    }\n",
    "\n",
    "def normalize_dimension(descriptors):\n",
    "    \"\"\"Take in a list of descriptor tuples and output metadata for a single field group.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    descriptors: list of tuple descriptors describing a single field group.\n",
    "    \"\"\"\n",
    "    # Categorical\n",
    "    if all(d[1] == 'category' for d in descriptors):\n",
    "        return normalize_categorical(descriptors)\n",
    "    # Numerical\n",
    "    elif all((d[1] in ['exact', 'range']) for d in descriptors):\n",
    "        return normalize_numerical(descriptors)\n",
    "    # Mixed\n",
    "    else:\n",
    "        print(descriptors)\n",
    "        raise Exception('Bad descriptors')\n",
    "\n",
    "def normalize_descriptors(descriptors):\n",
    "    \"\"\"Take in a list of list of descriptor tuples, one for each dimension, and output\n",
    "    metadata for the table.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    descriptors: list of list of tuple descriptors describing multiple field groups.\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    edges = []\n",
    "    labels = []\n",
    "    order = []\n",
    "    types = []\n",
    "    # Extract metadata for each dimension and concatenate\n",
    "    for dimension in descriptors:\n",
    "        normalized = normalize_dimension(dimension)\n",
    "        names.append(normalized['name'])\n",
    "        edges.append(normalized['edges'])\n",
    "        labels.append(normalized['labels'])\n",
    "        types.append(normalized['type'])\n",
    "        order.append(normalized['order'])\n",
    "    name = ' by '.join(names)\n",
    "    return {\n",
    "        'name': name,\n",
    "        'names': names,\n",
    "        'edges': edges,\n",
    "        'labels': labels,\n",
    "        'na': ['.', ''],\n",
    "        'types': types,\n",
    "        'order': order\n",
    "    }\n",
    "\n",
    "parsed_names = set()\n",
    "parsed_variables = []\n",
    "\n",
    "for group in variables:\n",
    "    label_dict = {}\n",
    "    labels = make_labels(group)\n",
    "    # Extract descriptors for fields from patterns\n",
    "    for label_group in labels:\n",
    "        for label in label_group:\n",
    "            for pattern, parser in patterns[label_group]:\n",
    "                m = re.search(pattern, label)\n",
    "                if m:\n",
    "                    p = parser(m)\n",
    "                    if not isinstance(p, list):\n",
    "                        p = [p]\n",
    "                    label_dict[label] = p\n",
    "                    break\n",
    "       \n",
    "    first_var = group.flatten()[0]\n",
    "    d = len(first_var.fields)\n",
    "    \n",
    "    # Group descriptors into list structure\n",
    "    # List of list of descriptor tuples\n",
    "    descriptors = [list() for i in range(d - 1)]\n",
    "    for var in group.ravel():\n",
    "        # For each field dimension\n",
    "        for i in range(d - 1):\n",
    "            # Extract the descriptor for the field\n",
    "            descriptor = label_dict[var.fields[i + 1]]\n",
    "            # Add to data structure\n",
    "            if not descriptor in descriptors[i]:\n",
    "                descriptors[i].append(descriptor)\n",
    "    \n",
    "    # In the case of multiple descriptors returned for a single field, take all combinations\n",
    "    for indices in itertools.product(*[range(len(d[0])) for d in descriptors]):\n",
    "        # Get only the descriptors for the particular combination described by indices\n",
    "        sub_descriptors = [list() for i in range(d - 1)]\n",
    "        for i in range(d - 1):\n",
    "            for desc in descriptors[i]:\n",
    "                sub_descriptors[i].append(desc[indices[i]])\n",
    "        \n",
    "        # Normalize\n",
    "        desc = normalize_descriptors(sub_descriptors)\n",
    "        \n",
    "        # Apply ordering\n",
    "        desc_vars = group.copy()\n",
    "        for i in range(d - 1):\n",
    "            if desc['order'][i]:\n",
    "                order = desc['order'][i]\n",
    "                desc_vars = np.swapaxes(np.swapaxes(desc_vars, 0, i)[order], 0, i)\n",
    "        del desc['order']\n",
    "        \n",
    "        # Convert variables to variable ids and convert to list structure\n",
    "        desc_vars = np.array(\n",
    "            [v.id for v in desc_vars.ravel()]\n",
    "        ).reshape(desc_vars.shape).tolist()\n",
    "        \n",
    "        desc['fields'] = desc_vars\n",
    "        \n",
    "        # Get descriptions\n",
    "        tableId = first_var.id.split(\"_\")[0]\n",
    "        desc['description'] = data['tables'][tableId]['description']\n",
    "        desc['type'] = 'Histogram'\n",
    "        \n",
    "        # Add to global list\n",
    "        parsed_variables.append(desc)\n",
    "        if desc['name'] in parsed_names:\n",
    "            raise Exception('Duplicate Variable: %s' % desc['name'])\n",
    "        parsed_names.add(desc['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('normalized_variables.json', 'w') as f:\n",
    "    json.dump(parsed_variables, f, sort_keys=True, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transportation (0)\n",
      "work from home (1)\n",
      "household income (2)\n",
      "earnings (3)\n",
      "investment income (4)\n",
      "supplemental security income (5)\n",
      "assistance income (6)\n",
      "retirement income (7)\n",
      "other income (8)\n",
      "food stamps by disability (9)\n",
      "own_rent (10)\n",
      "householder race (11)\n",
      "own_rent by householder age (12)\n",
      "own_rent by household size (13)\n",
      "own_rent by education (14)\n",
      "own_rent by rooms (15)\n",
      "num units (16)\n",
      "building type (17)\n",
      "own_rent by num units (18)\n",
      "own_rent by building type (19)\n",
      "own_rent by built (20)\n",
      "own_rent by moved in (21)\n",
      "fuel source (22)\n",
      "own_rent by bedrooms (23)\n",
      "pay for utility (24)\n",
      "poverty to income (25)\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate(parsed_variables):\n",
    "    print('%s (%d)' % (v['name'], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Tenure By Age Of Householder',\n",
       " 'edges': [None, [15, 25, 35, 45, 55, 60, 65, 75, 85, inf]],\n",
       " 'fields': [['B25007_003',\n",
       "   'B25007_004',\n",
       "   'B25007_005',\n",
       "   'B25007_006',\n",
       "   'B25007_007',\n",
       "   'B25007_008',\n",
       "   'B25007_009',\n",
       "   'B25007_010',\n",
       "   'B25007_011'],\n",
       "  ['B25007_013',\n",
       "   'B25007_014',\n",
       "   'B25007_015',\n",
       "   'B25007_016',\n",
       "   'B25007_017',\n",
       "   'B25007_018',\n",
       "   'B25007_019',\n",
       "   'B25007_020',\n",
       "   'B25007_021']],\n",
       " 'labels': [['own', 'rent'], None],\n",
       " 'na': ['.', ''],\n",
       " 'name': 'own_rent by householder age',\n",
       " 'names': ['own_rent', 'householder age'],\n",
       " 'type': 'Histogram',\n",
       " 'types': ['Categorical', 'Continuous']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_variables[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# yes_count = 0\n",
    "# no_count = 0\n",
    "\n",
    "# population_patterns = [' for (.*)$', '%\\s*(.*?):*\\s*$', '.* FOR (.*?)$']\n",
    "\n",
    "# bins = set()\n",
    "\n",
    "# for i, table in enumerate(tables):\n",
    "#     varlist = [data['variables'][variableId] for variableId in table['variables'] if (variabledId in selected_variables)]\n",
    "#     print(varlist)\n",
    "#     if len(varlist) == 0:\n",
    "#         print(table)\n",
    "#         break\n",
    "#     descriptions = [var['description'] for var in varlist]\n",
    "#     population = None\n",
    "#     for patt in population_patterns:\n",
    "#         match = re.search(patt, descriptions[0])\n",
    "#         if match:\n",
    "#             population = match.group(1)\n",
    "#     split_length = max(len(normalize_desc(desc).split('%')) for desc in descriptions)\n",
    "#     deepest = [normalize_desc(desc) for desc in descriptions if len(normalize_desc(desc).split('%')) == split_length]\n",
    "#     if split_length == 1 and len(deepest) > 1:\n",
    "#         raise Exception('No detail')\n",
    "        \n",
    "#     groups = []\n",
    "#     for desc in deepest:\n",
    "#         desc = desc\n",
    "#         for j, census_bin in enumerate(desc.split('%')[1:]):\n",
    "#             while len(groups) <= j:\n",
    "#                 groups.append(set())\n",
    "#             b = normalize_bin(census_bin)\n",
    "#             if b == '':\n",
    "#                 break\n",
    "#             groups[j].add(b)\n",
    "#     for group in groups:\n",
    "#         bins.add(frozenset(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
